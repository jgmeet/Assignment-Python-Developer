{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46df6d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f447316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to convert PDF pages to images\n",
    "def pdf_to_images(pdf_path):\n",
    "    images = []\n",
    "    with fitz.open(pdf_path) as pdf_file:\n",
    "        for page_num in range(len(pdf_file)):\n",
    "            page = pdf_file.load_page(page_num)\n",
    "            pixmap = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pixmap.width, pixmap.height], pixmap.samples)\n",
    "            images.append(img)\n",
    "            \n",
    "    return images\n",
    "\n",
    "\n",
    "def extract_text_eng(pdf_file_path):\n",
    "    # Convert PDF pages to images\n",
    "    images = pdf_to_images(pdf_file_path)\n",
    "    text = \"\"\n",
    "    for img in images:\n",
    "        # Function to perform OCR on images using Tesseract\n",
    "        text += pytesseract.image_to_string(img) + \"\\n\"\n",
    "        \n",
    "    return text\n",
    "\n",
    "def extract_text_chin(pdf_file_path):\n",
    "    # Convert PDF pages to images\n",
    "    images = pdf_to_images(pdf_file_path)\n",
    "    text = \"\"\n",
    "    for img in images:\n",
    "        text += pytesseract.image_to_string(img, lang='chi_sim') + \"\\n\"\n",
    "        \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f1966cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your PDF files\n",
    "english_pdf_path = \"c330302f-bfdd-4c79-a5ac-614446292e68.pdf\"\n",
    "chinese_pdf_path = \"d6ecaee0-a2ac-495d-b375-41b8008dffe8.pdf\"\n",
    "\n",
    "# Extract text from English PDF\n",
    "english_text = extract_text_eng(english_pdf_path)\n",
    "\n",
    "# Extract text from Chinese PDF\n",
    "chinese_text = extract_text_chin(chinese_pdf_path)\n",
    "\n",
    "# Split text into segments\n",
    "english_segments = english_text.split(\"\\n\")\n",
    "chinese_segments = chinese_text.split(\"\\n\")\n",
    "\n",
    "# Ensure the number of segments is the same\n",
    "min_length = min(len(english_segments), len(chinese_segments))\n",
    "english_segments = english_segments[:min_length]\n",
    "chinese_segments = chinese_segments[:min_length]\n",
    "\n",
    "# Create translation dataset\n",
    "translation_dataset = list(zip(english_segments, chinese_segments))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678c3b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
